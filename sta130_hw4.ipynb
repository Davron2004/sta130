{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd803b32",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/66ff69e6-1ab8-800d-a495-f14107545152"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf02922",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Basically, standard deviation says about how much the data is spread out, and standard error of the mean says how much the mean of the dataset is trustworthy, the less - the better\n",
    "\n",
    "So, while the standard deviation of a dataset is about how much the data varies, the standart error of mean is a good prediction of how much the mean of the dataset would vary if you were to take new other datapoints or add datapoints to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8616c4ec",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "To create an n% confidence interval we need to first calculate the SEM, then find the critical value for the required confidence level from the critical value table. In particular, the critical value for 95% is 1.96, so we calculate the confidence interval by the formula (mean +- 1.96 * SEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7096d24",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Alternatively to calculating SEM we can just take the 97.5th and 2.5th percentiles of bootstrapped means instead of making calculations; matter fact, ChatGPT says it works better for non-normal distributed data samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8295a583",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfda4b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Bootstrap Confidence Interval for the Mean: (47.276635751407504, 50.62851486440195)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Generate a random normally distributed sample\n",
    "np.random.seed(42)  # For reproducibility\n",
    "sample = np.random.normal(loc=50, scale=10, size=100)  # Mean=50, SD=10, Sample size=100\n",
    "\n",
    "# Step 2: Define the bootstrap function\n",
    "def bootstrap_ci(data, statistic_func, n_bootstrap=1000, ci_percentile=95):\n",
    "    bootstrapped_stats = []\n",
    "    \n",
    "    # Generate bootstrap samples and calculate the statistic for each sample\n",
    "    for _ in range(n_bootstrap):\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)  # Sample with replacement\n",
    "        stat = statistic_func(bootstrap_sample) # in our case it's the mean\n",
    "        bootstrapped_stats.append(stat)\n",
    "    \n",
    "    # Sort bootstrapped statistics\n",
    "    bootstrapped_stats = np.sort(bootstrapped_stats)\n",
    "    \n",
    "    # Calculate the percentiles for the confidence interval\n",
    "    lower_bound = np.percentile(bootstrapped_stats, (100 - ci_percentile) / 2)\n",
    "    upper_bound = np.percentile(bootstrapped_stats, 100 - (100 - ci_percentile) / 2)\n",
    "    \n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Step 3: Calculate the 95% confidence interval for the mean\n",
    "ci_mean = bootstrap_ci(sample, np.mean, n_bootstrap=1000, ci_percentile=95)\n",
    "print(f\"95% Bootstrap Confidence Interval for the Mean: {ci_mean}\")\n",
    "\n",
    "# this function is really good because we can use it not only for mean but for basically any other statistic very easily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c552fcaf",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "We use the confidence interval to say the range of sample statistics that are likely to contain the true population parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a03866",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "1. Bootstrapping is when you take a sample of size n, then create a bunch of other samples also of size n only using the elements from the original sample. Duplicates are allowed.\n",
    "2. To see how much the statistic values might vary if we added more sample data\n",
    "3. I would bootstrap the sample data a bunch of times (between 1.000 and 10.000 times, depending on how big the provided sample is) so that I see how much the statistics from my sample could be close to the true values by calculating how big are confidence intervals. For example, if my statistic is in the 95% confidence interval and I don't consider the size of the interval to be big then I would say that my statistic is pretty accurate. For example if I had a sample of male heights and the mean would be 170 with the 95% confidence interval of 168 and 172 then I would consider my sample mean to be pretty accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac0610",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "\n",
    "The fact that the confidence interval covers zero means that the fact that the drug has zero effect is very much in the confidence interval which basically means that the fact that the drug has very little to no effect is very possible. If, for example, the 95% confidence interval did not cover zero it would mean that there is a 95% chance that the drug does have an effect; but if that's not the case then we cannot reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d5f97",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "\n",
    "The null hypothesis in this case would be that the drug had no effect, and in our case it would be true if patients didn't have health score increases on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc23fea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample statistics 81.0 84.3\n",
      "bootstrapped statistics (79.2, 82.6) (83.0, 85.4)\n",
      "healthdiffs 3.3 (0.9, 5.6)\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "s = \"\"\"PatientID,Age,Gender,InitialHealthScore,FinalHealthScore\n",
    "1,45,M,84,86\n",
    "2,34,F,78,86\n",
    "3,29,M,83,80\n",
    "4,52,F,81,86\n",
    "5,37,M,81,84\n",
    "6,41,F,80,86\n",
    "7,33,M,79,86\n",
    "8,48,F,85,82\n",
    "9,26,M,76,83\n",
    "10,39,F,83,84\"\"\"\n",
    "\n",
    "sample_data = pd.read_csv(StringIO(s))\n",
    "sample_data['healthdiff'] = sample_data['FinalHealthScore'] - sample_data['InitialHealthScore']\n",
    "\n",
    "mean_initialhealth = np.mean(sample_data['InitialHealthScore'])\n",
    "mean_finalhealth = np.mean(sample_data['FinalHealthScore'])\n",
    "mean_diff = np.mean(sample_data['healthdiff'])\n",
    "btrp_mean_diff = bootstrap_ci(sample_data['healthdiff'], np.mean)\n",
    "btrp_mean_initialhealth = bootstrap_ci(sample_data['InitialHealthScore'], np.mean)\n",
    "btrp_mean_finalhealth = bootstrap_ci(sample_data['FinalHealthScore'], np.mean)\n",
    "print(\"sample statistics\", mean_initialhealth, mean_finalhealth)\n",
    "print(\"bootstrapped statistics\", btrp_mean_initialhealth, btrp_mean_finalhealth)\n",
    "print(\"healthdiffs\", mean_diff, btrp_mean_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9503e5f",
   "metadata": {},
   "source": [
    "As we can see the average healthdiffs in the dataset are 3.3 increase and the 95% confidence interval for healthdiffs does not cover zero which means that we basically rejected the null hypothesis in our case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
