{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd803b32",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Basically, standard deviation says about how much the data is spread out, and standard error of the mean says how much the mean of the dataset is trustworthy, the less - the better\n",
    "\n",
    "So, while the standard deviation of a dataset is about how much the data varies, the standart error of mean is a good prediction of how much the mean of the dataset would vary if you were to take new other datapoints or add datapoints to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92983dc0",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "To create an n% confidence interval we need to first calculate the SEM, then find the critical value for the required confidence level from the critical value table. In particular, the critical value for 95% is 1.96, so we calculate the confidence interval by the formula (mean +- 1.96 * SEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd329af",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Alternatively to calculating SEM we can just take the 97.5th and 2.5th percentiles of bootstrapped means instead of making calculations; matter fact, ChatGPT says it works better for non-normal distributed data samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45904a30",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d331f288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Bootstrap Confidence Interval for the Mean: (47.276635751407504, 50.62851486440195)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Generate a random normally distributed sample\n",
    "np.random.seed(42)  # For reproducibility\n",
    "sample = np.random.normal(loc=50, scale=10, size=100)  # Mean=50, SD=10, Sample size=100\n",
    "\n",
    "# Step 2: Define the bootstrap function\n",
    "def bootstrap_ci(data, statistic_func, n_bootstrap=1000, ci_percentile=95):\n",
    "    bootstrapped_stats = []\n",
    "    \n",
    "    # Generate bootstrap samples and calculate the statistic for each sample\n",
    "    for _ in range(n_bootstrap):\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)  # Sample with replacement\n",
    "        stat = statistic_func(bootstrap_sample) # in our case it's the mean\n",
    "        bootstrapped_stats.append(stat)\n",
    "    \n",
    "    # Sort bootstrapped statistics\n",
    "    bootstrapped_stats = np.sort(bootstrapped_stats)\n",
    "    \n",
    "    # Calculate the percentiles for the confidence interval\n",
    "    lower_bound = np.percentile(bootstrapped_stats, (100 - ci_percentile) / 2)\n",
    "    upper_bound = np.percentile(bootstrapped_stats, 100 - (100 - ci_percentile) / 2)\n",
    "    \n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Step 3: Calculate the 95% confidence interval for the mean\n",
    "ci_mean = bootstrap_ci(sample, np.mean, n_bootstrap=1000, ci_percentile=95)\n",
    "print(f\"95% Bootstrap Confidence Interval for the Mean: {ci_mean}\")\n",
    "\n",
    "# this function is really good because we can use it not only for mean but for basically any other statistic very easily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b8683",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "We use the confidence interval to say the range of sample statistics that are likely to contain the true population parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bd0365",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "1. Bootstrapping is when you take a sample of size n, then create a bunch of other samples also of size n only using the elements from the original sample. Duplicates are allowed.\n",
    "2. To see how much the statistic values might vary if we added more sample data\n",
    "3. I would bootstrap the sample data a bunch of times (between 1.000 and 10.000 times, depending on how big the provided sample is) so that I see how much the statistics from my sample could be close to the true values by calculating how big are confidence intervals. For example, if my statistic is in the 95% confidence interval and I don't consider the size of the interval to be big then I would "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
